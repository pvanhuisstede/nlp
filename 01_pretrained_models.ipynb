{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "#|default_exp pretrained_models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP with pre-trained models: spaCy and Stanford NLP\n",
    "(follows: )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import spacy\n",
    "en = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of text: <class 'str'>\n",
      "Length of text: 169\n"
     ]
    }
   ],
   "source": [
    "#| export\n",
    "text = (\"Donald John Trump (born June 14, 1946) is the 45th and former president of \"\n",
    "        \"the United States.  Before entering politics, he was a businessman and television personality.\")\n",
    "\n",
    "print(f\"Type of text: {type(text)}\")\n",
    "print(f\"Length of text: {len(text)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By applying the spaCy model we assigned to the variable `en`. We can generate a processed document wit spaCy, `doc_en` that has sentences and tokens:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "doc_en = en(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Donald John Trump (born June 14, 1946) is the 45th and former president of the United States.,\n",
       "  Before entering politics, he was a businessman and television personality.]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| export\n",
    "list(doc_en.sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "#| export\n",
    "print(len(list(doc_en.sents)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tbody>\n",
       "<tr><td>Donald     </td></tr>\n",
       "<tr><td>John       </td></tr>\n",
       "<tr><td>Trump      </td></tr>\n",
       "<tr><td>(          </td></tr>\n",
       "<tr><td>born       </td></tr>\n",
       "<tr><td>June       </td></tr>\n",
       "<tr><td>14         </td></tr>\n",
       "<tr><td>,          </td></tr>\n",
       "<tr><td>1946       </td></tr>\n",
       "<tr><td>)          </td></tr>\n",
       "<tr><td>is         </td></tr>\n",
       "<tr><td>the        </td></tr>\n",
       "<tr><td>45th       </td></tr>\n",
       "<tr><td>and        </td></tr>\n",
       "<tr><td>former     </td></tr>\n",
       "<tr><td>president  </td></tr>\n",
       "<tr><td>of         </td></tr>\n",
       "<tr><td>the        </td></tr>\n",
       "<tr><td>United     </td></tr>\n",
       "<tr><td>States     </td></tr>\n",
       "<tr><td>.          </td></tr>\n",
       "<tr><td>           </td></tr>\n",
       "<tr><td>Before     </td></tr>\n",
       "<tr><td>entering   </td></tr>\n",
       "<tr><td>politics   </td></tr>\n",
       "<tr><td>,          </td></tr>\n",
       "<tr><td>he         </td></tr>\n",
       "<tr><td>was        </td></tr>\n",
       "<tr><td>a          </td></tr>\n",
       "<tr><td>businessman</td></tr>\n",
       "<tr><td>and        </td></tr>\n",
       "<tr><td>television </td></tr>\n",
       "<tr><td>personality</td></tr>\n",
       "<tr><td>.          </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#| export\n",
    "from IPython.display import display_html\n",
    "import tabulate\n",
    "\n",
    "tokens = [[t] for t in doc_en]\n",
    "display(display_html(tabulate.tabulate(tokens, tablefmt='html')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "spaCy also identifies a number of linguistic features for every token: `lemma`, `pos_` (the universal POS tags), and `tag_`(contains the more finegrained, language-specific POS tags):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tbody>\n",
       "<tr><td>Donald     </td><td>Donald     </td><td>PROPN</td><td>NNP  </td></tr>\n",
       "<tr><td>John       </td><td>John       </td><td>PROPN</td><td>NNP  </td></tr>\n",
       "<tr><td>Trump      </td><td>Trump      </td><td>PROPN</td><td>NNP  </td></tr>\n",
       "<tr><td>(          </td><td>(          </td><td>PUNCT</td><td>-LRB-</td></tr>\n",
       "<tr><td>born       </td><td>bear       </td><td>VERB </td><td>VBN  </td></tr>\n",
       "<tr><td>June       </td><td>June       </td><td>PROPN</td><td>NNP  </td></tr>\n",
       "<tr><td>14         </td><td>14         </td><td>NUM  </td><td>CD   </td></tr>\n",
       "<tr><td>,          </td><td>,          </td><td>PUNCT</td><td>,    </td></tr>\n",
       "<tr><td>1946       </td><td>1946       </td><td>NUM  </td><td>CD   </td></tr>\n",
       "<tr><td>)          </td><td>)          </td><td>PUNCT</td><td>-RRB-</td></tr>\n",
       "<tr><td>is         </td><td>be         </td><td>AUX  </td><td>VBZ  </td></tr>\n",
       "<tr><td>the        </td><td>the        </td><td>DET  </td><td>DT   </td></tr>\n",
       "<tr><td>45th       </td><td>45th       </td><td>ADJ  </td><td>JJ   </td></tr>\n",
       "<tr><td>and        </td><td>and        </td><td>CCONJ</td><td>CC   </td></tr>\n",
       "<tr><td>former     </td><td>former     </td><td>ADJ  </td><td>JJ   </td></tr>\n",
       "<tr><td>president  </td><td>president  </td><td>NOUN </td><td>NN   </td></tr>\n",
       "<tr><td>of         </td><td>of         </td><td>ADP  </td><td>IN   </td></tr>\n",
       "<tr><td>the        </td><td>the        </td><td>DET  </td><td>DT   </td></tr>\n",
       "<tr><td>United     </td><td>United     </td><td>PROPN</td><td>NNP  </td></tr>\n",
       "<tr><td>States     </td><td>States     </td><td>PROPN</td><td>NNP  </td></tr>\n",
       "<tr><td>.          </td><td>.          </td><td>PUNCT</td><td>.    </td></tr>\n",
       "<tr><td>           </td><td>           </td><td>SPACE</td><td>_SP  </td></tr>\n",
       "<tr><td>Before     </td><td>before     </td><td>ADP  </td><td>IN   </td></tr>\n",
       "<tr><td>entering   </td><td>enter      </td><td>VERB </td><td>VBG  </td></tr>\n",
       "<tr><td>politics   </td><td>politic    </td><td>NOUN </td><td>NNS  </td></tr>\n",
       "<tr><td>,          </td><td>,          </td><td>PUNCT</td><td>,    </td></tr>\n",
       "<tr><td>he         </td><td>he         </td><td>PRON </td><td>PRP  </td></tr>\n",
       "<tr><td>was        </td><td>be         </td><td>AUX  </td><td>VBD  </td></tr>\n",
       "<tr><td>a          </td><td>a          </td><td>DET  </td><td>DT   </td></tr>\n",
       "<tr><td>businessman</td><td>businessman</td><td>NOUN </td><td>NN   </td></tr>\n",
       "<tr><td>and        </td><td>and        </td><td>CCONJ</td><td>CC   </td></tr>\n",
       "<tr><td>television </td><td>television </td><td>NOUN </td><td>NN   </td></tr>\n",
       "<tr><td>personality</td><td>personality</td><td>NOUN </td><td>NN   </td></tr>\n",
       "<tr><td>.          </td><td>.          </td><td>PUNCT</td><td>.    </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "features = [[t.orth_, t.lemma_, t.pos_, t.tag_] for t in doc_en]\n",
    "display(display_html(tabulate.tabulate(features, tablefmt='html')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "spaCy also offers pre-trained models for NER (Named Entity Recognition). The results can be found on the `ent_iob_` and `ent_type_` attributes.\n",
    "\n",
    "The `ent_type_` attribute informs us about what type of entity the token refers to: 'Donald Trump' => person, 'June 14, 1946' => date, '45th' => ordinal number, and 'the United States' => GPE (Geo Political Entity).\n",
    "\n",
    "The `ent_iob_` attribute gives, by way of the letters 'I,O,B' the position of the token in the entity, where `O` means that the token is outside of an entity, `B` the entity is at the beginning of a token, and `I` means it is inside a token. So basically the IOB scheme gives you information about begin and parts of entities (positional)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tbody>\n",
       "<tr><td>Donald     </td><td>B</td><td>PERSON </td></tr>\n",
       "<tr><td>John       </td><td>I</td><td>PERSON </td></tr>\n",
       "<tr><td>Trump      </td><td>I</td><td>PERSON </td></tr>\n",
       "<tr><td>(          </td><td>O</td><td>       </td></tr>\n",
       "<tr><td>born       </td><td>O</td><td>       </td></tr>\n",
       "<tr><td>June       </td><td>B</td><td>DATE   </td></tr>\n",
       "<tr><td>14         </td><td>I</td><td>DATE   </td></tr>\n",
       "<tr><td>,          </td><td>I</td><td>DATE   </td></tr>\n",
       "<tr><td>1946       </td><td>I</td><td>DATE   </td></tr>\n",
       "<tr><td>)          </td><td>O</td><td>       </td></tr>\n",
       "<tr><td>is         </td><td>O</td><td>       </td></tr>\n",
       "<tr><td>the        </td><td>O</td><td>       </td></tr>\n",
       "<tr><td>45th       </td><td>B</td><td>ORDINAL</td></tr>\n",
       "<tr><td>and        </td><td>O</td><td>       </td></tr>\n",
       "<tr><td>former     </td><td>O</td><td>       </td></tr>\n",
       "<tr><td>president  </td><td>O</td><td>       </td></tr>\n",
       "<tr><td>of         </td><td>O</td><td>       </td></tr>\n",
       "<tr><td>the        </td><td>B</td><td>GPE    </td></tr>\n",
       "<tr><td>United     </td><td>I</td><td>GPE    </td></tr>\n",
       "<tr><td>States     </td><td>I</td><td>GPE    </td></tr>\n",
       "<tr><td>.          </td><td>O</td><td>       </td></tr>\n",
       "<tr><td>           </td><td>O</td><td>       </td></tr>\n",
       "<tr><td>Before     </td><td>O</td><td>       </td></tr>\n",
       "<tr><td>entering   </td><td>O</td><td>       </td></tr>\n",
       "<tr><td>politics   </td><td>O</td><td>       </td></tr>\n",
       "<tr><td>,          </td><td>O</td><td>       </td></tr>\n",
       "<tr><td>he         </td><td>O</td><td>       </td></tr>\n",
       "<tr><td>was        </td><td>O</td><td>       </td></tr>\n",
       "<tr><td>a          </td><td>O</td><td>       </td></tr>\n",
       "<tr><td>businessman</td><td>O</td><td>       </td></tr>\n",
       "<tr><td>and        </td><td>O</td><td>       </td></tr>\n",
       "<tr><td>television </td><td>O</td><td>       </td></tr>\n",
       "<tr><td>personality</td><td>O</td><td>       </td></tr>\n",
       "<tr><td>.          </td><td>O</td><td>       </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "entities = [(t.orth_, t.ent_iob_, t.ent_type_) for t in doc_en]\n",
    "display(display_html(tabulate.tabulate(entities, tablefmt='html')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can access the recognized entities directly when we use the `ents` attribute of the document directly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Donald John Trump', 'PERSON'), ('June 14, 1946', 'DATE'), ('45th', 'ORDINAL'), ('the United States', 'GPE')]\n"
     ]
    }
   ],
   "source": [
    "print([(ent.text, ent.label_) for ent in doc_en.ents])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On top of all this, the spaCy model also has a dependency parser on board that analyzes the grammatical realtions between the tokens:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "syntax = [[token.text, token.dep_, token.head.text] for token in doc_en]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We display the results, kept in the variable `syntax`, in the usual way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tbody>\n",
       "<tr><td>Donald     </td><td>compound</td><td>Trump      </td></tr>\n",
       "<tr><td>John       </td><td>compound</td><td>Trump      </td></tr>\n",
       "<tr><td>Trump      </td><td>nsubj   </td><td>is         </td></tr>\n",
       "<tr><td>(          </td><td>punct   </td><td>Trump      </td></tr>\n",
       "<tr><td>born       </td><td>acl     </td><td>Trump      </td></tr>\n",
       "<tr><td>June       </td><td>npadvmod</td><td>born       </td></tr>\n",
       "<tr><td>14         </td><td>nummod  </td><td>June       </td></tr>\n",
       "<tr><td>,          </td><td>punct   </td><td>June       </td></tr>\n",
       "<tr><td>1946       </td><td>nummod  </td><td>June       </td></tr>\n",
       "<tr><td>)          </td><td>punct   </td><td>Trump      </td></tr>\n",
       "<tr><td>is         </td><td>ROOT    </td><td>is         </td></tr>\n",
       "<tr><td>the        </td><td>det     </td><td>45th       </td></tr>\n",
       "<tr><td>45th       </td><td>attr    </td><td>is         </td></tr>\n",
       "<tr><td>and        </td><td>cc      </td><td>45th       </td></tr>\n",
       "<tr><td>former     </td><td>amod    </td><td>president  </td></tr>\n",
       "<tr><td>president  </td><td>conj    </td><td>45th       </td></tr>\n",
       "<tr><td>of         </td><td>prep    </td><td>president  </td></tr>\n",
       "<tr><td>the        </td><td>det     </td><td>States     </td></tr>\n",
       "<tr><td>United     </td><td>compound</td><td>States     </td></tr>\n",
       "<tr><td>States     </td><td>pobj    </td><td>of         </td></tr>\n",
       "<tr><td>.          </td><td>punct   </td><td>is         </td></tr>\n",
       "<tr><td>           </td><td>dep     </td><td>was        </td></tr>\n",
       "<tr><td>Before     </td><td>prep    </td><td>was        </td></tr>\n",
       "<tr><td>entering   </td><td>pcomp   </td><td>Before     </td></tr>\n",
       "<tr><td>politics   </td><td>dobj    </td><td>entering   </td></tr>\n",
       "<tr><td>,          </td><td>punct   </td><td>was        </td></tr>\n",
       "<tr><td>he         </td><td>nsubj   </td><td>was        </td></tr>\n",
       "<tr><td>was        </td><td>ROOT    </td><td>was        </td></tr>\n",
       "<tr><td>a          </td><td>det     </td><td>personality</td></tr>\n",
       "<tr><td>businessman</td><td>nmod    </td><td>personality</td></tr>\n",
       "<tr><td>and        </td><td>cc      </td><td>businessman</td></tr>\n",
       "<tr><td>television </td><td>conj    </td><td>businessman</td></tr>\n",
       "<tr><td>personality</td><td>attr    </td><td>was        </td></tr>\n",
       "<tr><td>.          </td><td>punct   </td><td>was        </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(display_html(tabulate.tabulate(syntax, tablefmt='html')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multilingual NLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be inferred from the spaCy model we called this model is based on and targeted at the English language.\n",
    "\n",
    "One can use the spaCy website to select models to use for different usecases:\n",
    "\n",
    "https://spacy.io/usage/models\n",
    "\n",
    "But models for other languages are also available. Let's try one out on a Dutch text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "nl = spacy.load('nl_core_news_sm')\n",
    "text_nl = (\"Mark Rutte is minister-president van Nederland.\" \"Hij is van de VVD en heeft een slecht geheugen.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_nl = nl(text_nl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the Dutch model was trained in its particular way, there are differences with the English model.\n",
    "\n",
    "The most important is that the Dutch models do not offer lemmatization, the `lemma_` attribute returns the `orth_` attribute.\n",
    "\n",
    "NB. whenever numbers turn up in the tables that are generated, they refer to the ID's of tokens in vectorspace. This usually means that we specified the attribute of a token `ent_iob` without the ending underscore: `ent_iob_`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tbody>\n",
       "<tr><td>mark              </td><td>PROPN</td><td>SPEC|deeleigen                   </td><td>B</td><td>PERSON</td></tr>\n",
       "<tr><td>rutte             </td><td>PROPN</td><td>SPEC|deeleigen                   </td><td>I</td><td>PERSON</td></tr>\n",
       "<tr><td>is                </td><td>AUX  </td><td>WW|pv|tgw|ev                     </td><td>O</td><td>      </td></tr>\n",
       "<tr><td>minister-president</td><td>NOUN </td><td>N|soort|ev|basis|zijd|stan       </td><td>O</td><td>      </td></tr>\n",
       "<tr><td>van               </td><td>ADP  </td><td>VZ|init                          </td><td>O</td><td>      </td></tr>\n",
       "<tr><td>nederland         </td><td>PROPN</td><td>N|eigen|ev|basis|onz|stan        </td><td>B</td><td>GPE   </td></tr>\n",
       "<tr><td>.                 </td><td>PUNCT</td><td>LET                              </td><td>O</td><td>      </td></tr>\n",
       "<tr><td>hij               </td><td>PRON </td><td>VNW|pers|pron|nomin|vol|3|ev|masc</td><td>O</td><td>      </td></tr>\n",
       "<tr><td>is                </td><td>AUX  </td><td>WW|pv|tgw|ev                     </td><td>O</td><td>      </td></tr>\n",
       "<tr><td>van               </td><td>ADP  </td><td>VZ|init                          </td><td>O</td><td>      </td></tr>\n",
       "<tr><td>de                </td><td>DET  </td><td>LID|bep|stan|rest                </td><td>O</td><td>      </td></tr>\n",
       "<tr><td>vvd               </td><td>PROPN</td><td>N|eigen|ev|basis|zijd|stan       </td><td>B</td><td>ORG   </td></tr>\n",
       "<tr><td>en                </td><td>CCONJ</td><td>VG|neven                         </td><td>O</td><td>      </td></tr>\n",
       "<tr><td>hebben            </td><td>VERB </td><td>WW|pv|tgw|met-t                  </td><td>O</td><td>      </td></tr>\n",
       "<tr><td>een               </td><td>DET  </td><td>LID|onbep|stan|agr               </td><td>O</td><td>      </td></tr>\n",
       "<tr><td>slecht            </td><td>ADJ  </td><td>ADJ|prenom|basis|zonder          </td><td>O</td><td>      </td></tr>\n",
       "<tr><td>geheugen          </td><td>NOUN </td><td>N|soort|mv|basis                 </td><td>O</td><td>      </td></tr>\n",
       "<tr><td>.                 </td><td>PUNCT</td><td>LET                              </td><td>O</td><td>      </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "info = [(t.lemma_, t.pos_, t.tag_, t.ent_iob_, t.ent_type_) for t in doc_nl]\n",
    "display(display_html(tabulate.tabulate(info, tablefmt='html')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If one is working with Dutch texts, then the Python library **StanfordNLP** that is build on top of PyTorchprovides a fully neural pipeline with lemmatization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use device: gpu\n",
      "---\n",
      "Loading: tokenize\n",
      "With settings: \n",
      "{'model_path': '/home/peter/stanfordnlp_resources/nl_alpino_models/nl_alpino_tokenizer.pt', 'lang': 'nl', 'shorthand': 'nl_alpino', 'mode': 'predict'}\n",
      "---\n",
      "Loading: pos\n",
      "With settings: \n",
      "{'model_path': '/home/peter/stanfordnlp_resources/nl_alpino_models/nl_alpino_tagger.pt', 'pretrain_path': '/home/peter/stanfordnlp_resources/nl_alpino_models/nl_alpino.pretrain.pt', 'lang': 'nl', 'shorthand': 'nl_alpino', 'mode': 'predict'}\n",
      "---\n",
      "Loading: lemma\n",
      "With settings: \n",
      "{'model_path': '/home/peter/stanfordnlp_resources/nl_alpino_models/nl_alpino_lemmatizer.pt', 'lang': 'nl', 'shorthand': 'nl_alpino', 'mode': 'predict'}\n",
      "Building an attentional Seq2Seq model...\n",
      "Using a Bi-LSTM encoder\n",
      "Using soft attention for LSTM.\n",
      "Finetune all embeddings.\n",
      "[Running seq2seq lemmatizer with edit classifier]\n",
      "---\n",
      "Loading: depparse\n",
      "With settings: \n",
      "{'model_path': '/home/peter/stanfordnlp_resources/nl_alpino_models/nl_alpino_parser.pt', 'pretrain_path': '/home/peter/stanfordnlp_resources/nl_alpino_models/nl_alpino.pretrain.pt', 'lang': 'nl', 'shorthand': 'nl_alpino', 'mode': 'predict'}\n",
      "Done loading processors!\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "import stanfordnlp\n",
    "\n",
    "#stanfordnlp.download('nl') # just run this once.\n",
    "nl_stanford = stanfordnlp.Pipeline(lang='nl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nRuntimeError: \"index_select_out_cuda_impl\" not implemented for \\'Float\\'\\n'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The following line throws an error\n",
    "# TODO: debug\n",
    "# doc_nl_stanford = nl_stanford(text_nl)\n",
    "\"\"\"\n",
    "RuntimeError: \"index_select_out_cuda_impl\" not implemented for 'Float'\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The other thing we tried, in the cell below, is to run the Stanford library using a spaCy pipeline. But this also throws an error: A missing `vocab` attribute in the pipeline.\n",
    "\n",
    "TODO: Solve this first: stanford nlp called as a spaCy library makes sense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Install this library with pip\\nfrom spacy_stanfordnlp import StanfordNLPLanguage\\n\\nsnlp = stanfordnlp.Pipeline(lang=\"nl\")\\nnlp = StanfordNLPLanguage(snlp)\\n'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# Install this library with pip\n",
    "from spacy_stanfordnlp import StanfordNLPLanguage\n",
    "\n",
    "snlp = stanfordnlp.Pipeline(lang=\"nl\")\n",
    "nlp = StanfordNLPLanguage(snlp)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try to use a lemmatizer as such."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatizer(texts):\n",
    "  docs = nl.pipe(texts)\n",
    "  texts = [text.replace(\"\\n\", \"\").strip() for text in texts]\n",
    "  cleaned_lemmas = [[t.lemma_ for t in doc] for doc in docs]\n",
    "  return cleaned_lemmas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['m'], ['a'], ['r'], ['k'], [' '], ['r'], ['u'], ['t'], ['t'], ['e'], [' '], ['i'], ['s'], [' '], ['m'], ['i'], ['n'], ['i'], ['s'], ['t'], ['e'], ['r'], ['-'], ['p'], ['r'], ['e'], ['s'], ['i'], ['d'], ['e'], ['n'], ['t'], [' '], ['v'], ['a'], ['n'], [' '], ['n'], ['e'], ['d'], ['e'], ['r'], ['l'], ['a'], ['n'], ['d'], ['.'], ['h'], ['i'], ['j'], [' '], ['i'], ['s'], [' '], ['v'], ['a'], ['n'], [' '], ['d'], ['e'], [' '], ['v'], ['v'], ['d'], [' '], ['e'], ['n'], [' '], ['h'], ['e'], ['e'], ['f'], ['t'], [' '], ['e'], ['e'], ['n'], [' '], ['s'], ['l'], ['e'], ['c'], ['h'], ['t'], [' '], ['g'], ['e'], ['h'], ['e'], ['u'], ['g'], ['e'], ['n'], ['.']]\n"
     ]
    }
   ],
   "source": [
    "cleaned = lemmatizer(text_nl)\n",
    "print(cleaned)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add a lookup based lemmatizer for Dutch:\n",
    "\n",
    "https://github.com/explosion/spaCy/blob/master/spacy/lang/de/tokenizer_exceptions.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0a2ef650857c097cc4b789456eae376654e6121eead7baaf4f6a1af0eeae8bb5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
