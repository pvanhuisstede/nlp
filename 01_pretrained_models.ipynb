{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "#| default_exp pretrained_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "%matplotlib inline\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import spacy\n",
    "from IPython.display import display_html\n",
    "import tabulate\n",
    "import stanza\n",
    "import spacy_stanza"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP with pre-trained models: spaCy and Stanford NLP\n",
    "(follows: )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "en = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of text: <class 'str'>\n",
      "Length of text: 169\n"
     ]
    }
   ],
   "source": [
    "#| export\n",
    "text = (\"Donald John Trump (born June 14, 1946) is the 45th and former president of \"\n",
    "        \"the United States.  Before entering politics, he was a businessman and television personality.\")\n",
    "\n",
    "print(f\"Type of text: {type(text)}\")\n",
    "print(f\"Length of text: {len(text)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By applying the spaCy model we assigned to the variable `en`. We can generate a processed document wit spaCy, `doc_en` that has sentences and tokens:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "doc_en = en(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Donald John Trump (born June 14, 1946) is the 45th and former president of the United States.  ,\n",
       " Before entering politics, he was a businessman and television personality.]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| export\n",
    "list(doc_en.sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "#| export\n",
    "print(len(list(doc_en.sents)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tbody>\n",
       "<tr><td>Donald     </td></tr>\n",
       "<tr><td>John       </td></tr>\n",
       "<tr><td>Trump      </td></tr>\n",
       "<tr><td>(          </td></tr>\n",
       "<tr><td>born       </td></tr>\n",
       "<tr><td>June       </td></tr>\n",
       "<tr><td>14         </td></tr>\n",
       "<tr><td>,          </td></tr>\n",
       "<tr><td>1946       </td></tr>\n",
       "<tr><td>)          </td></tr>\n",
       "<tr><td>is         </td></tr>\n",
       "<tr><td>the        </td></tr>\n",
       "<tr><td>45th       </td></tr>\n",
       "<tr><td>and        </td></tr>\n",
       "<tr><td>former     </td></tr>\n",
       "<tr><td>president  </td></tr>\n",
       "<tr><td>of         </td></tr>\n",
       "<tr><td>the        </td></tr>\n",
       "<tr><td>United     </td></tr>\n",
       "<tr><td>States     </td></tr>\n",
       "<tr><td>.          </td></tr>\n",
       "<tr><td>           </td></tr>\n",
       "<tr><td>Before     </td></tr>\n",
       "<tr><td>entering   </td></tr>\n",
       "<tr><td>politics   </td></tr>\n",
       "<tr><td>,          </td></tr>\n",
       "<tr><td>he         </td></tr>\n",
       "<tr><td>was        </td></tr>\n",
       "<tr><td>a          </td></tr>\n",
       "<tr><td>businessman</td></tr>\n",
       "<tr><td>and        </td></tr>\n",
       "<tr><td>television </td></tr>\n",
       "<tr><td>personality</td></tr>\n",
       "<tr><td>.          </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#| export\n",
    "tokens = [[t] for t in doc_en]\n",
    "display(display_html(tabulate.tabulate(tokens, tablefmt='html')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "spaCy also identifies a number of linguistic features for every token: `lemma`, `pos_` (the universal POS tags), and `tag_`(contains the more finegrained, language-specific POS tags):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tbody>\n",
       "<tr><td>Donald     </td><td>Donald     </td><td>PROPN</td><td>NNP  </td></tr>\n",
       "<tr><td>John       </td><td>John       </td><td>PROPN</td><td>NNP  </td></tr>\n",
       "<tr><td>Trump      </td><td>Trump      </td><td>PROPN</td><td>NNP  </td></tr>\n",
       "<tr><td>(          </td><td>(          </td><td>PUNCT</td><td>-LRB-</td></tr>\n",
       "<tr><td>born       </td><td>bear       </td><td>VERB </td><td>VBN  </td></tr>\n",
       "<tr><td>June       </td><td>June       </td><td>PROPN</td><td>NNP  </td></tr>\n",
       "<tr><td>14         </td><td>14         </td><td>NUM  </td><td>CD   </td></tr>\n",
       "<tr><td>,          </td><td>,          </td><td>PUNCT</td><td>,    </td></tr>\n",
       "<tr><td>1946       </td><td>1946       </td><td>NUM  </td><td>CD   </td></tr>\n",
       "<tr><td>)          </td><td>)          </td><td>PUNCT</td><td>-RRB-</td></tr>\n",
       "<tr><td>is         </td><td>be         </td><td>AUX  </td><td>VBZ  </td></tr>\n",
       "<tr><td>the        </td><td>the        </td><td>DET  </td><td>DT   </td></tr>\n",
       "<tr><td>45th       </td><td>45th       </td><td>ADJ  </td><td>JJ   </td></tr>\n",
       "<tr><td>and        </td><td>and        </td><td>CCONJ</td><td>CC   </td></tr>\n",
       "<tr><td>former     </td><td>former     </td><td>ADJ  </td><td>JJ   </td></tr>\n",
       "<tr><td>president  </td><td>president  </td><td>NOUN </td><td>NN   </td></tr>\n",
       "<tr><td>of         </td><td>of         </td><td>ADP  </td><td>IN   </td></tr>\n",
       "<tr><td>the        </td><td>the        </td><td>DET  </td><td>DT   </td></tr>\n",
       "<tr><td>United     </td><td>United     </td><td>PROPN</td><td>NNP  </td></tr>\n",
       "<tr><td>States     </td><td>States     </td><td>PROPN</td><td>NNP  </td></tr>\n",
       "<tr><td>.          </td><td>.          </td><td>PUNCT</td><td>.    </td></tr>\n",
       "<tr><td>           </td><td>           </td><td>SPACE</td><td>_SP  </td></tr>\n",
       "<tr><td>Before     </td><td>before     </td><td>ADP  </td><td>IN   </td></tr>\n",
       "<tr><td>entering   </td><td>enter      </td><td>VERB </td><td>VBG  </td></tr>\n",
       "<tr><td>politics   </td><td>politic    </td><td>NOUN </td><td>NNS  </td></tr>\n",
       "<tr><td>,          </td><td>,          </td><td>PUNCT</td><td>,    </td></tr>\n",
       "<tr><td>he         </td><td>he         </td><td>PRON </td><td>PRP  </td></tr>\n",
       "<tr><td>was        </td><td>be         </td><td>AUX  </td><td>VBD  </td></tr>\n",
       "<tr><td>a          </td><td>a          </td><td>DET  </td><td>DT   </td></tr>\n",
       "<tr><td>businessman</td><td>businessman</td><td>NOUN </td><td>NN   </td></tr>\n",
       "<tr><td>and        </td><td>and        </td><td>CCONJ</td><td>CC   </td></tr>\n",
       "<tr><td>television </td><td>television </td><td>NOUN </td><td>NN   </td></tr>\n",
       "<tr><td>personality</td><td>personality</td><td>NOUN </td><td>NN   </td></tr>\n",
       "<tr><td>.          </td><td>.          </td><td>PUNCT</td><td>.    </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#| export\n",
    "features = [[t.orth_, t.lemma_, t.pos_, t.tag_] for t in doc_en]\n",
    "display(display_html(tabulate.tabulate(features, tablefmt='html')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "spaCy also offers pre-trained models for NER (Named Entity Recognition). The results can be found on the `ent_iob_` and `ent_type_` attributes.\n",
    "\n",
    "The `ent_type_` attribute informs us about what type of entity the token refers to: 'Donald Trump' => person, 'June 14, 1946' => date, '45th' => ordinal number, and 'the United States' => GPE (Geo Political Entity).\n",
    "\n",
    "The `ent_iob_` attribute gives, by way of the letters 'I,O,B' the position of the token in the entity, where `O` means that the token is outside of an entity, `B` the entity is at the beginning of a token, and `I` means it is inside a token. So basically the IOB scheme gives you information about begin and parts of entities (positional)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tbody>\n",
       "<tr><td>Donald     </td><td>B</td><td>PERSON </td></tr>\n",
       "<tr><td>John       </td><td>I</td><td>PERSON </td></tr>\n",
       "<tr><td>Trump      </td><td>I</td><td>PERSON </td></tr>\n",
       "<tr><td>(          </td><td>O</td><td>       </td></tr>\n",
       "<tr><td>born       </td><td>O</td><td>       </td></tr>\n",
       "<tr><td>June       </td><td>B</td><td>DATE   </td></tr>\n",
       "<tr><td>14         </td><td>I</td><td>DATE   </td></tr>\n",
       "<tr><td>,          </td><td>I</td><td>DATE   </td></tr>\n",
       "<tr><td>1946       </td><td>I</td><td>DATE   </td></tr>\n",
       "<tr><td>)          </td><td>O</td><td>       </td></tr>\n",
       "<tr><td>is         </td><td>O</td><td>       </td></tr>\n",
       "<tr><td>the        </td><td>O</td><td>       </td></tr>\n",
       "<tr><td>45th       </td><td>B</td><td>ORDINAL</td></tr>\n",
       "<tr><td>and        </td><td>O</td><td>       </td></tr>\n",
       "<tr><td>former     </td><td>O</td><td>       </td></tr>\n",
       "<tr><td>president  </td><td>O</td><td>       </td></tr>\n",
       "<tr><td>of         </td><td>O</td><td>       </td></tr>\n",
       "<tr><td>the        </td><td>B</td><td>GPE    </td></tr>\n",
       "<tr><td>United     </td><td>I</td><td>GPE    </td></tr>\n",
       "<tr><td>States     </td><td>I</td><td>GPE    </td></tr>\n",
       "<tr><td>.          </td><td>O</td><td>       </td></tr>\n",
       "<tr><td>           </td><td>O</td><td>       </td></tr>\n",
       "<tr><td>Before     </td><td>O</td><td>       </td></tr>\n",
       "<tr><td>entering   </td><td>O</td><td>       </td></tr>\n",
       "<tr><td>politics   </td><td>O</td><td>       </td></tr>\n",
       "<tr><td>,          </td><td>O</td><td>       </td></tr>\n",
       "<tr><td>he         </td><td>O</td><td>       </td></tr>\n",
       "<tr><td>was        </td><td>O</td><td>       </td></tr>\n",
       "<tr><td>a          </td><td>O</td><td>       </td></tr>\n",
       "<tr><td>businessman</td><td>O</td><td>       </td></tr>\n",
       "<tr><td>and        </td><td>O</td><td>       </td></tr>\n",
       "<tr><td>television </td><td>O</td><td>       </td></tr>\n",
       "<tr><td>personality</td><td>O</td><td>       </td></tr>\n",
       "<tr><td>.          </td><td>O</td><td>       </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#| export\n",
    "entities = [(t.orth_, t.ent_iob_, t.ent_type_) for t in doc_en]\n",
    "display(display_html(tabulate.tabulate(entities, tablefmt='html')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can access the recognized entities directly when we use the `ents` attribute of the document directly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Donald John Trump', 'PERSON'), ('June 14, 1946', 'DATE'), ('45th', 'ORDINAL'), ('the United States', 'GPE')]\n"
     ]
    }
   ],
   "source": [
    "#| export\n",
    "print([(ent.text, ent.label_) for ent in doc_en.ents])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On top of all this, the spaCy model also has a dependency parser on board that analyzes the grammatical realtions between the tokens:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "syntax = [[token.text, token.dep_, token.head.text] for token in doc_en]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We display the results, kept in the variable `syntax`, in the usual way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tbody>\n",
       "<tr><td>Donald     </td><td>compound</td><td>Trump      </td></tr>\n",
       "<tr><td>John       </td><td>compound</td><td>Trump      </td></tr>\n",
       "<tr><td>Trump      </td><td>nsubj   </td><td>is         </td></tr>\n",
       "<tr><td>(          </td><td>punct   </td><td>Trump      </td></tr>\n",
       "<tr><td>born       </td><td>acl     </td><td>Trump      </td></tr>\n",
       "<tr><td>June       </td><td>npadvmod</td><td>born       </td></tr>\n",
       "<tr><td>14         </td><td>nummod  </td><td>June       </td></tr>\n",
       "<tr><td>,          </td><td>punct   </td><td>June       </td></tr>\n",
       "<tr><td>1946       </td><td>nummod  </td><td>June       </td></tr>\n",
       "<tr><td>)          </td><td>punct   </td><td>Trump      </td></tr>\n",
       "<tr><td>is         </td><td>ROOT    </td><td>is         </td></tr>\n",
       "<tr><td>the        </td><td>det     </td><td>45th       </td></tr>\n",
       "<tr><td>45th       </td><td>attr    </td><td>is         </td></tr>\n",
       "<tr><td>and        </td><td>cc      </td><td>45th       </td></tr>\n",
       "<tr><td>former     </td><td>amod    </td><td>president  </td></tr>\n",
       "<tr><td>president  </td><td>conj    </td><td>45th       </td></tr>\n",
       "<tr><td>of         </td><td>prep    </td><td>president  </td></tr>\n",
       "<tr><td>the        </td><td>det     </td><td>States     </td></tr>\n",
       "<tr><td>United     </td><td>compound</td><td>States     </td></tr>\n",
       "<tr><td>States     </td><td>pobj    </td><td>of         </td></tr>\n",
       "<tr><td>.          </td><td>punct   </td><td>is         </td></tr>\n",
       "<tr><td>           </td><td>dep     </td><td>.          </td></tr>\n",
       "<tr><td>Before     </td><td>prep    </td><td>was        </td></tr>\n",
       "<tr><td>entering   </td><td>pcomp   </td><td>Before     </td></tr>\n",
       "<tr><td>politics   </td><td>dobj    </td><td>entering   </td></tr>\n",
       "<tr><td>,          </td><td>punct   </td><td>was        </td></tr>\n",
       "<tr><td>he         </td><td>nsubj   </td><td>was        </td></tr>\n",
       "<tr><td>was        </td><td>ROOT    </td><td>was        </td></tr>\n",
       "<tr><td>a          </td><td>det     </td><td>businessman</td></tr>\n",
       "<tr><td>businessman</td><td>nmod    </td><td>personality</td></tr>\n",
       "<tr><td>and        </td><td>cc      </td><td>businessman</td></tr>\n",
       "<tr><td>television </td><td>compound</td><td>personality</td></tr>\n",
       "<tr><td>personality</td><td>attr    </td><td>was        </td></tr>\n",
       "<tr><td>.          </td><td>punct   </td><td>was        </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(display_html(tabulate.tabulate(syntax, tablefmt='html')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multilingual NLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be inferred from the spaCy model we called this model is based on and targeted at the English language.\n",
    "\n",
    "One can use the spaCy website to select models to use for different usecases:\n",
    "\n",
    "https://spacy.io/usage/models\n",
    "\n",
    "But models for other languages are also available. Let's try one out on a Dutch text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "nl = spacy.load('nl_core_news_sm')\n",
    "text_nl = (\"Mark Rutte is minister-president van Nederland.\" \"Hij is van de VVD en heeft een slecht geheugen.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "doc_nl = nl(text_nl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the Dutch model was trained in its particular way, there are differences with the English model.\n",
    "\n",
    "The most important is that the Dutch models do not offer lemmatization, the `lemma_` attribute returns the `orth_` attribute.\n",
    "\n",
    "NB. whenever numbers turn up in the tables that are generated, they refer to the ID's of tokens in vectorspace. This usually means that we specified the attribute of a token `ent_iob` without the ending underscore: `ent_iob_`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tbody>\n",
       "<tr><td>Mark             </td><td>PROPN</td><td>SPEC|deeleigen                   </td><td>B</td><td>PERSON</td></tr>\n",
       "<tr><td>Rutte            </td><td>PROPN</td><td>SPEC|deeleigen                   </td><td>O</td><td>      </td></tr>\n",
       "<tr><td>zijn             </td><td>AUX  </td><td>WW|pv|tgw|ev                     </td><td>O</td><td>      </td></tr>\n",
       "<tr><td>ministerpresident</td><td>NOUN </td><td>N|soort|ev|basis|zijd|stan       </td><td>O</td><td>      </td></tr>\n",
       "<tr><td>van              </td><td>ADP  </td><td>VZ|init                          </td><td>O</td><td>      </td></tr>\n",
       "<tr><td>Nederland        </td><td>PROPN</td><td>N|eigen|ev|basis|onz|stan        </td><td>B</td><td>GPE   </td></tr>\n",
       "<tr><td>.                </td><td>PUNCT</td><td>LET                              </td><td>O</td><td>      </td></tr>\n",
       "<tr><td>hij              </td><td>PRON </td><td>VNW|pers|pron|nomin|vol|3|ev|masc</td><td>O</td><td>      </td></tr>\n",
       "<tr><td>zijn             </td><td>AUX  </td><td>WW|pv|tgw|ev                     </td><td>O</td><td>      </td></tr>\n",
       "<tr><td>van              </td><td>ADP  </td><td>VZ|init                          </td><td>O</td><td>      </td></tr>\n",
       "<tr><td>de               </td><td>DET  </td><td>LID|bep|stan|rest                </td><td>O</td><td>      </td></tr>\n",
       "<tr><td>VVD              </td><td>PROPN</td><td>N|eigen|ev|basis|zijd|stan       </td><td>B</td><td>ORG   </td></tr>\n",
       "<tr><td>en               </td><td>CCONJ</td><td>VG|neven                         </td><td>O</td><td>      </td></tr>\n",
       "<tr><td>hebben           </td><td>VERB </td><td>WW|pv|tgw|met-t                  </td><td>O</td><td>      </td></tr>\n",
       "<tr><td>een              </td><td>DET  </td><td>LID|onbep|stan|agr               </td><td>O</td><td>      </td></tr>\n",
       "<tr><td>slecht           </td><td>ADJ  </td><td>ADJ|prenom|basis|zonder          </td><td>O</td><td>      </td></tr>\n",
       "<tr><td>geheug           </td><td>NOUN </td><td>N|soort|mv|basis                 </td><td>O</td><td>      </td></tr>\n",
       "<tr><td>.                </td><td>PUNCT</td><td>LET                              </td><td>O</td><td>      </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#| export\n",
    "info = [(t.lemma_, t.pos_, t.tag_, t.ent_iob_, t.ent_type_) for t in doc_nl]\n",
    "display(display_html(tabulate.tabulate(info, tablefmt='html')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If one is working with Dutch texts, then the Python library **stanza** is the one to use (in the Telematika notebook the stanfordnlp library is used, but this library is not recommended anymore.)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c12ed76f27b54f37b56a647c71670aad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.4.0.json:   0%|   …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-29 16:39:16 INFO: Loading these models for language: nl (Dutch):\n",
      "=======================\n",
      "| Processor | Package |\n",
      "-----------------------\n",
      "| tokenize  | alpino  |\n",
      "| pos       | alpino  |\n",
      "| lemma     | alpino  |\n",
      "| depparse  | alpino  |\n",
      "| ner       | conll02 |\n",
      "=======================\n",
      "\n",
      "2022-08-29 16:39:16 INFO: Use device: cpu\n",
      "2022-08-29 16:39:16 INFO: Loading: tokenize\n",
      "2022-08-29 16:39:16 INFO: Loading: pos\n",
      "2022-08-29 16:39:16 INFO: Loading: lemma\n",
      "2022-08-29 16:39:16 INFO: Loading: depparse\n",
      "2022-08-29 16:39:17 INFO: Loading: ner\n",
      "2022-08-29 16:39:17 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "# we ran 'stanza.download('nl') in the terminal\n",
    "nl_nlp = stanza.Pipeline('nl', use_gpu=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_nl_stanza = nl_nlp(text_nl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Still get this to work with GPU, but so far, so good. We now have access, via the model, to text and lemma, but also to the attributes `upos`, `xpos`, `govenor`, and `dependency_relation`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stanza_info = []\n",
    "for sentence in doc_nl_stanza.sentences:\n",
    "  for word in sentence.words:\n",
    "    stanza_info.append((len(stanza_info)+1, word.text, word.lemma, word.pos, word.upos, word.xpos, word.deprel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tbody>\n",
       "<tr><td style=\"text-align: right;\"> 1</td><td>Mark              </td><td>Mark              </td><td>PROPN</td><td>PROPN</td><td>SPEC|deeleigen                   </td><td>nsubj</td></tr>\n",
       "<tr><td style=\"text-align: right;\"> 2</td><td>Rutte             </td><td>Rutte             </td><td>PROPN</td><td>PROPN</td><td>SPEC|deeleigen                   </td><td>flat </td></tr>\n",
       "<tr><td style=\"text-align: right;\"> 3</td><td>is                </td><td>zijn              </td><td>AUX  </td><td>AUX  </td><td>WW|pv|tgw|ev                     </td><td>cop  </td></tr>\n",
       "<tr><td style=\"text-align: right;\"> 4</td><td>minister-president</td><td>minister_president</td><td>NOUN </td><td>NOUN </td><td>N|soort|ev|basis|zijd|stan       </td><td>root </td></tr>\n",
       "<tr><td style=\"text-align: right;\"> 5</td><td>van               </td><td>van               </td><td>ADP  </td><td>ADP  </td><td>VZ|init                          </td><td>case </td></tr>\n",
       "<tr><td style=\"text-align: right;\"> 6</td><td>Nederland         </td><td>Nederland         </td><td>PROPN</td><td>PROPN</td><td>N|eigen|ev|basis|onz|stan        </td><td>nmod </td></tr>\n",
       "<tr><td style=\"text-align: right;\"> 7</td><td>.                 </td><td>.                 </td><td>PUNCT</td><td>PUNCT</td><td>LET                              </td><td>punct</td></tr>\n",
       "<tr><td style=\"text-align: right;\"> 8</td><td>Hij               </td><td>hij               </td><td>PRON </td><td>PRON </td><td>VNW|pers|pron|nomin|vol|3|ev|masc</td><td>nsubj</td></tr>\n",
       "<tr><td style=\"text-align: right;\"> 9</td><td>is                </td><td>zijn              </td><td>AUX  </td><td>AUX  </td><td>WW|pv|tgw|ev                     </td><td>root </td></tr>\n",
       "<tr><td style=\"text-align: right;\">10</td><td>van               </td><td>van               </td><td>ADP  </td><td>ADP  </td><td>VZ|init                          </td><td>case </td></tr>\n",
       "<tr><td style=\"text-align: right;\">11</td><td>de                </td><td>de                </td><td>DET  </td><td>DET  </td><td>LID|bep|stan|rest                </td><td>det  </td></tr>\n",
       "<tr><td style=\"text-align: right;\">12</td><td>VVD               </td><td>VVD               </td><td>PROPN</td><td>PROPN</td><td>N|eigen|ev|basis|zijd|stan       </td><td>obl  </td></tr>\n",
       "<tr><td style=\"text-align: right;\">13</td><td>en                </td><td>en                </td><td>CCONJ</td><td>CCONJ</td><td>VG|neven                         </td><td>cc   </td></tr>\n",
       "<tr><td style=\"text-align: right;\">14</td><td>heeft             </td><td>hebben            </td><td>VERB </td><td>VERB </td><td>WW|pv|tgw|met-t                  </td><td>conj </td></tr>\n",
       "<tr><td style=\"text-align: right;\">15</td><td>een               </td><td>een               </td><td>DET  </td><td>DET  </td><td>LID|onbep|stan|agr               </td><td>det  </td></tr>\n",
       "<tr><td style=\"text-align: right;\">16</td><td>slecht            </td><td>slecht            </td><td>ADJ  </td><td>ADJ  </td><td>ADJ|prenom|basis|zonder          </td><td>amod </td></tr>\n",
       "<tr><td style=\"text-align: right;\">17</td><td>geheugen          </td><td>geheug            </td><td>NOUN </td><td>NOUN </td><td>N|soort|ev|basis|onz|stan        </td><td>obj  </td></tr>\n",
       "<tr><td style=\"text-align: right;\">18</td><td>.                 </td><td>.                 </td><td>PUNCT</td><td>PUNCT</td><td>LET                              </td><td>punct</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_html(tabulate.tabulate(stanza_info, tablefmt='html'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining spaCy and Stanza\n",
    "\n",
    "Thanks to the spacy-stanza wrapper we can combine the 2 libraries in pipelines. First we install `spacy_stanza` with Pip."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9b73465a11d4102a8bc99bfa49f3d10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.4.0.json:   0%|   …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-29 21:00:33 INFO: Loading these models for language: nl (Dutch):\n",
      "=======================\n",
      "| Processor | Package |\n",
      "-----------------------\n",
      "| tokenize  | alpino  |\n",
      "| pos       | alpino  |\n",
      "| lemma     | alpino  |\n",
      "| depparse  | alpino  |\n",
      "| ner       | conll02 |\n",
      "=======================\n",
      "\n",
      "2022-08-29 21:00:33 INFO: Use device: cpu\n",
      "2022-08-29 21:00:33 INFO: Loading: tokenize\n",
      "2022-08-29 21:00:33 INFO: Loading: pos\n",
      "2022-08-29 21:00:33 INFO: Loading: lemma\n",
      "2022-08-29 21:00:33 INFO: Loading: depparse\n",
      "2022-08-29 21:00:33 INFO: Loading: ner\n",
      "2022-08-29 21:00:34 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "nlp_spacy_stanza = spacy_stanza.load_pipeline('nl', use_gpu=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mark Mark PROPN nsubj PER\n",
      "Rutte Rutte PROPN flat PER\n",
      "is zijn AUX cop \n",
      "minister-president minister_president NOUN root \n",
      "van van ADP case \n",
      "Nederland Nederland PROPN nmod LOC\n",
      ". . PUNCT punct \n",
      "Hij hij PRON nsubj \n",
      "is zijn AUX root \n",
      "van van ADP case \n",
      "de de DET det \n",
      "VVD VVD PROPN obl ORG\n",
      "en en CCONJ cc \n",
      "heeft hebben VERB conj \n",
      "een een DET det \n",
      "slecht slecht ADJ advmod \n",
      "actief actief ADJ amod \n",
      "geheugen geheug NOUN obj \n",
      ". . PUNCT punct \n",
      "(Mark Rutte, Nederland, VVD)\n"
     ]
    }
   ],
   "source": [
    "doc_nlp_spacy_stanza = nlp_spacy_stanza(\"Mark Rutte is minister-president van Nederland.\" \"Hij is van de VVD en heeft een slecht actief geheugen.\")\n",
    "for token in doc_nlp_spacy_stanza:\n",
    "  print(token.text, token.lemma_, token.pos_, token.dep_, token.ent_type_)\n",
    "print(doc_nlp_spacy_stanza.ents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
