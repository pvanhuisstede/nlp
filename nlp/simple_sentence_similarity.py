# AUTOGENERATED! DO NOT EDIT! File to edit: ../07_simple_sentence_similarity.ipynb.

# %% auto 0
__all__ = ['sts_dev', 'sts_test', 'sick_train', 'sick_dev', 'sick_test', 'sick_all', 'STOP', 'PATH_TO_WORD2VEC', 'PATH_TO_GLOVE',
           'word2vec', 'PATH_TO_FREQUENCIES_FILE', 'PATH_TO_DOC_FREQUENCIES_FILE', 'frequencies', 'doc_frequencies',
           'benchmarks', 'pearson_results', 'spearman_results', 'pearson_results_df', 'spearman_results_df',
           'load_sts_dataset', 'download_sick', 'Sentence', 'read_tsv', 'run_avg_benchmark', 'run_wmd_benchmark',
           'remove_first_principal_component', 'run_sif_benchmark', 'run_experiment']

# %% ../07_simple_sentence_similarity.ipynb 4
import pandas as pd
import numpy as np
import scipy
import math
import os
import tensorflow as tf
import matplotlib.pyplot as plt
import seaborn as sns
import nltk
import requests
import gensim
from gensim.models import Word2Vec
from gensim.scripts.glove2word2vec import glove2word2vec
import csv
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.decomposition import TruncatedSVD
from collections import Counter
import torch
import tensorflow_hub as hub
import functools as ft

# %% ../07_simple_sentence_similarity.ipynb 5
def load_sts_dataset(filename):
  """ Loads a subset of the STS dataset into a DataFrame. In particular both sentences and their human rated similarity score."""
  sent_pairs = []
  with open(filename, "r") as f:
    for line in f:
      ts = line.strip().split('\t')
      sent_pairs.append((ts[5], ts[6], float(ts[4])))
  return pd.DataFrame(sent_pairs, columns=["sent_1", "sent_2", "sim"])

"""
# commented out: We will use the local downloaded files
def download_and_load_sts_data():
  # We will grab the STS datasets from their website.
  sts_dataset = tf.keras.utils.get_file(
    fname="Stsbenchmark.tar.gz",
    origin="http://ixa2.si.ehu.es/stswiki/images/4/48/Stsbenchmark.tar.gz",
    extract=True
  )
"""

sts_dev = load_sts_dataset('/home/peter/Documents/data/nlp/stsbenchmark/sts-dev.csv')
sts_test = load_sts_dataset('/home/peter/Documents/data/nlp/stsbenchmark/sts-test.csv')

# %% ../07_simple_sentence_similarity.ipynb 9
def download_sick(f): 

    response = requests.get(f).text

    lines = response.split("\n")[1:]
    lines = [l.split("\t") for l in lines if len(l) > 0]
    lines = [l for l in lines if len(l) == 5]

    df = pd.DataFrame(lines, columns=["idx", "sent_1", "sent_2", "sim", "label"])
    df['sim'] = pd.to_numeric(df['sim'])
    return df
    
sick_train = download_sick("https://raw.githubusercontent.com/alvations/stasis/master/SICK-data/SICK_train.txt")
sick_dev = download_sick("https://raw.githubusercontent.com/alvations/stasis/master/SICK-data/SICK_trial.txt")
sick_test = download_sick("https://raw.githubusercontent.com/alvations/stasis/master/SICK-data/SICK_test_annotated.txt")
sick_all = pd.concat([sick_train, sick_test, sick_dev])

# %% ../07_simple_sentence_similarity.ipynb 12
STOP = set(nltk.corpus.stopwords.words('english'))

class Sentence:
  def __init__(self, sentence):
    self.raw = sentence
    normalized_sentence = sentence.replace("‘", "'").replace("’", "'")
    self.tokens = [t.lower() for t in nltk.word_tokenize(normalized_sentence)]
    self.tokens_without_stop = [t for t in self.tokens if t not in STOP]

# %% ../07_simple_sentence_similarity.ipynb 14
PATH_TO_WORD2VEC = os.path.expanduser("~/Documents/data/nlp/GoogleNews-vectors-negative300.bin")
PATH_TO_GLOVE = os.path.expanduser("~/Documents/data/nlp/glove.840B.300d.txt")

word2vec = gensim.models.KeyedVectors.load_word2vec_format(PATH_TO_WORD2VEC, binary=True)

# %% ../07_simple_sentence_similarity.ipynb 16
PATH_TO_FREQUENCIES_FILE = os.path.expanduser('~/Documents/data/nlp/frequencies.tsv')
PATH_TO_DOC_FREQUENCIES_FILE = os.path.expanduser('~/Documents/data/nlp/doc_frequencies.tsv')

def read_tsv(f):
  frequencies = {}
  with open(f) as tsv:
    tsv_reader = csv.reader(tsv, delimiter='\t')
    for row in tsv_reader:
      frequencies[row[0]] = int(row[1])
  return frequencies

frequencies = read_tsv(PATH_TO_FREQUENCIES_FILE)
doc_frequencies = read_tsv(PATH_TO_DOC_FREQUENCIES_FILE)
doc_frequencies["NUM_DOCS"] = 1_288_431

# %% ../07_simple_sentence_similarity.ipynb 19
def run_avg_benchmark(sentences1, sentences2, model=None, use_stoplist=False, doc_freqs=None):
  if doc_freqs is not None:
    N = doc_freqs['NUM_DOCS']

  sims = []
  for (sent1, sent2) in zip(sentences1, sentences2):
    tokens1 = sent1.tokens_without_stop if use_stoplist else sent1.tokens
    tokens2 = sent2.tokens_without_stop if use_stoplist else sent2.tokens

    tokens1 = [token for token in tokens1 if token in model]
    tokens2 = [token for token in tokens2 if token in model]

    if len(tokens1) == 0 or len(tokens2) == 0:
      sims.append(0)
      continue

    tokfreqs1 = Counter(tokens1)
    tokfreqs2 = Counter(tokens2)
  
    weights1 = [tokfreqs1[token] * math.log(N/(doc_freqs.get(token, 0)+1)) 
                for token in tokfreqs1] if doc_freqs else None
    weights2 = [tokfreqs2[token] * math.log(N/(doc_freqs.get(token, 0)+1)) 
                for token in tokfreqs2] if doc_freqs else None
                
    embedding1 = np.average([model[token] for token in tokfreqs1], axis=0, weights=weights1).reshape(1, -1)
    embedding2 = np.average([model[token] for token in tokfreqs2], axis=0, weights=weights2).reshape(1, -1)

    sim = cosine_similarity(embedding1, embedding2)[0][0]
    sims.append(sim)

  return sims

# %% ../07_simple_sentence_similarity.ipynb 21
def run_wmd_benchmark(sentences1, sentences2, model, use_stoplist=False):
    
  sims = []
  for (sent1, sent2) in zip(sentences1, sentences2):
    
    tokens1 = sent1.tokens_without_stop if use_stoplist else sent1.tokens
    tokens2 = sent2.tokens_without_stop if use_stoplist else sent2.tokens
        
    tokens1 = [token for token in tokens1 if token in model]
    tokens2 = [token for token in tokens2 if token in model]
        
    if len(tokens1) == 0 or len(tokens2) == 0:
      tokens1 = [token for token in sent1.tokens if token in model]
      tokens2 = [token for token in sent2.tokens if token in model]
            
    sims.append(-model.wmdistance(tokens1, tokens2))
        
  return sims

# %% ../07_simple_sentence_similarity.ipynb 23
def remove_first_principal_component(X):
  svd = TruncatedSVD(n_components=1, n_iter=7, random_state=0)
  svd.fit(X)
  pc = svd.components_
  XX = X - X.dot(pc.transpose()) * pc
  return XX


def run_sif_benchmark(sentences1, sentences2, model, freqs={}, use_stoplist=False, a=0.001): 
  total_freq = sum(freqs.values())

  embeddings = []

  # SIF requires us to first collect all sentence embeddings and then perform 
  # common component analysis.
  for (sent1, sent2) in zip(sentences1, sentences2): 
      
    tokens1 = sent1.tokens_without_stop if use_stoplist else sent1.tokens
    tokens2 = sent2.tokens_without_stop if use_stoplist else sent2.tokens
      
    tokens1 = [token for token in tokens1 if token in model]
    tokens2 = [token for token in tokens2 if token in model]
      
    weights1 = [a/(a+freqs.get(token,0)/total_freq) for token in tokens1]
    weights2 = [a/(a+freqs.get(token,0)/total_freq) for token in tokens2]
      
    embedding1 = np.average([model[token] for token in tokens1], axis=0, weights=weights1)
    embedding2 = np.average([model[token] for token in tokens2], axis=0, weights=weights2)
      
    embeddings.append(embedding1)
    embeddings.append(embedding2)
      
  embeddings = remove_first_principal_component(np.array(embeddings))
  sims = [cosine_similarity(embeddings[idx*2].reshape(1, -1), 
                            embeddings[idx*2+1].reshape(1, -1))[0][0] 
          for idx in range(int(len(embeddings)/2))]

  return sims

# %% ../07_simple_sentence_similarity.ipynb 26
def run_experiment(df, benchmarks): 
    
    sentences1 = [Sentence(s) for s in df['sent_1']]
    sentences2 = [Sentence(s) for s in df['sent_2']]
    
    pearson_cors, spearman_cors = [], []
    for label, method in benchmarks:
        sims = method(sentences1, sentences2)
        pearson_correlation = scipy.stats.pearsonr(sims, df['sim'])[0]
        print(label, pearson_correlation)
        pearson_cors.append(pearson_correlation)
        spearman_correlation = scipy.stats.spearmanr(sims, df['sim'])[0]
        spearman_cors.append(spearman_correlation)
        
    return pearson_cors, spearman_cors

# %% ../07_simple_sentence_similarity.ipynb 27
benchmarks = [("AVG-W2V", ft.partial(run_avg_benchmark, model=word2vec, use_stoplist=False)),
              ("AVG-W2V-STOP", ft.partial(run_avg_benchmark, model=word2vec, use_stoplist=True)),
              ("AVG-W2V-TFIDF", ft.partial(run_avg_benchmark, model=word2vec, use_stoplist=False, doc_freqs=doc_frequencies)),
              ("AVG-W2V-TFIDF-STOP", ft.partial(run_avg_benchmark, model=word2vec, use_stoplist=True, doc_freqs=doc_frequencies)),
              ("WMD-W2V", ft.partial(run_wmd_benchmark, model=word2vec, use_stoplist=False)), 
              ("WMD-W2V-STOP", ft.partial(run_wmd_benchmark, model=word2vec, use_stoplist=True)), 
              ("SIF-W2V", ft.partial(run_sif_benchmark, freqs=frequencies, model=word2vec, use_stoplist=False)),
]

pearson_results, spearman_results = {}, {}
pearson_results["SICK-DEV"], spearman_results["SICK-DEV"] = run_experiment(sick_dev, benchmarks)
pearson_results["SICK-TEST"], spearman_results["SICK-TEST"] = run_experiment(sick_test, benchmarks)
pearson_results["STS-DEV"], spearman_results["STS-DEV"] = run_experiment(sts_dev, benchmarks)
pearson_results["STS-TEST"], spearman_results["STS-TEST"] = run_experiment(sts_test, benchmarks) 

# %% ../07_simple_sentence_similarity.ipynb 29
plt.rcParams['figure.figsize'] = (10,5)

pearson_results_df = pd.DataFrame(pearson_results)
pearson_results_df = pearson_results_df.transpose()
pearson_results_df = pearson_results_df.rename(columns={i:b[0] for i, b in enumerate(benchmarks)})

spearman_results_df = pd.DataFrame(spearman_results)
spearman_results_df = spearman_results_df.transpose()
spearman_results_df = spearman_results_df.rename(columns={i:b[0] for i, b in enumerate(benchmarks)})
